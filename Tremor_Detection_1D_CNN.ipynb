{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNngKS6qRVCjQuvVDT5guP5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Y9f0AHEQsBcs"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzRlmhZrmsC4",
        "outputId": "3799ebe7-f386-4b37-90da-1550c0398ffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KJx9-cy2u6Dv3KyotrhhXGRQ0vCWjo5Q\n",
            "To: /content/tremor_data.npz\n",
            "100%|██████████| 21.3M/21.3M [00:00<00:00, 119MB/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['features', 'labels']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# get tremor data (.npz file) from drive\n",
        "# link: https://drive.google.com/file/d/1KJx9-cy2u6Dv3KyotrhhXGRQ0vCWjo5Q/view?usp=drive_link\n",
        "!pip install gdown\n",
        "import gdown\n",
        "\n",
        "file_id = \"1KJx9-cy2u6Dv3KyotrhhXGRQ0vCWjo5Q\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", \"tremor_data.npz\", quiet=False)\n",
        "\n",
        "data = np.load('tremor_data.npz')\n",
        "print(data.files)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data is comprised of **feature arrays** and **label arrays** which have already been processed. Features are in 3 second segments, sampled at 100Hz so 300 data points, and across 3 dimensional channels, x y z."
      ],
      "metadata": {
        "id": "lT0VNh1Qo4tD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Feature array shape: {data['features'].shape}\")\n",
        "print(f\"Label array shape: {data['labels'].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfH0RG2RoBz7",
        "outputId": "1be09a17-3c36-4f2d-b0de-7d7c8b5de43f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature array shape: (3091, 300, 3)\n",
            "Label array shape: (3091,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = np.unique(data['labels'], return_counts=True)\n",
        "class_name = {0: 'non-tremor', 1: 'pre-tremor', 2: 'tremor'}\n",
        "label_counts = {class_name[int(lbl)]: int(count) for lbl, count in zip(counts[0], counts[1])}\n",
        "print(f\"Label Distribution: {label_counts}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ivwfjvUpvMq",
        "outputId": "bceb516b-c765-44d0-db3e-3d97e0dec694"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Distribution: {'non-tremor': 2997, 'pre-tremor': 28, 'tremor': 66}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are unexpectly a serious **class imbalance issue**, where non-tremor (label 0) has a greater presence than pre-tremor (label 1) and tremor (label 2). Something we can do before even training is **downsample the dominant class**, 'non-tremor'."
      ],
      "metadata": {
        "id": "2KriOPjZvhuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def downsample(signal, labels, percent_tremor=10):\n",
        "    '''\n",
        "    percent_tremor: Percent of samples that are labeled either 'pre-tremor' (1) or 'tremor' (2) in the downsampled dataset.\n",
        "    '''\n",
        "    count = np.unique(labels, return_counts=True)[1]\n",
        "    num_tremor = count[1] + count[2]\n",
        "    # adjust non tremor sample count\n",
        "    num_non_tremor = int((num_tremor / percent_tremor) * 100) - num_tremor\n",
        "    print(f'Downsampling to {num_non_tremor} of non-tremor samples from {count[0]}')\n",
        "    print(f'Downsampled set has {num_tremor} amount of positive tremor labels.')\n",
        "\n",
        "    if len(labels) - num_tremor < num_non_tremor:\n",
        "        print(f\"Chosen percent_tremor: {percent_tremor} is upsampling 'non_tremor' cases.\")\n",
        "        return signal, labels\n",
        "    else:\n",
        "        # get indicies of each sample with respective label\n",
        "        zero_mask = labels == 0\n",
        "        tremor_mask = labels !=0\n",
        "\n",
        "        # randomly select 'non_tremor' samples to keep\n",
        "        kept_zeroes = np.random.choice(np.where(zero_mask)[0], num_non_tremor, replace=False)\n",
        "        kept_sample_idx = np.concatenate((kept_zeroes, np.where(tremor_mask)[0]))\n",
        "        shuffled_idx = np.random.permutation(kept_sample_idx)\n",
        "\n",
        "        return signal[shuffled_idx], labels[shuffled_idx]"
      ],
      "metadata": {
        "id": "qauIfiisw2Ai"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "downsampled_signal, downsampled_labels = downsample(data['features'], data['labels'], percent_tremor=10)\n",
        "print(f\"Downsampled Feature array shape: {downsampled_signal.shape}\")\n",
        "print(f\"Downsampled Label array shape: {downsampled_labels.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m2YS7ei3m8M",
        "outputId": "07b4008c-2f08-43fb-f51c-d21e08454cb4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downsampling to 846 of non-tremor samples from 2997\n",
            "Downsampled set has 94 amount of positive tremor labels.\n",
            "Downsampled Feature array shape: (940, 300, 3)\n",
            "Downsampled Label array shape: (940,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create PyTorch dataset for tremor data."
      ],
      "metadata": {
        "id": "IG8WxmgTsmr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TremorDataset(Dataset):\n",
        "    def __init__(self, signal, labels):\n",
        "        '''\n",
        "        signal (ndarray): 3D array of shape (num_samples, num_points, num_channels)\n",
        "        labels (ndarray): 1D array of shape (num_samples,)\n",
        "        '''\n",
        "        # change signal dimension to (num_samples, num_channels, num_points) since 1D Conv passes over lowest dimension\n",
        "        self.signal = torch.tensor(signal, dtype=torch.float32).permute(0, 2, 1)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.signal[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "Aoyeimlhrdtx"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TremorDataset(downsampled_signal, downsampled_labels)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# one batch\n",
        "signal_batch, label_batch = next(iter(loader))\n",
        "print(signal_batch.shape) # expecting (B, channels, sequence) -> (B, 3, 300)\n",
        "print(label_batch.shape) # expecting (B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1b1Zvf33aFY",
        "outputId": "fa10e399-4ca5-4b76-a253-11eee11771fd"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 300])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model: 1D CNN**"
      ],
      "metadata": {
        "id": "uz96hzaS82Eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''GPT generated code'''\n",
        "class TremorCNN(nn.Module):\n",
        "    def __init__(self, num_channels=3, num_classes=3):\n",
        "        super(TremorCNN, self).__init__()\n",
        "\n",
        "        # Conv1: in_channels=3 (x,y,z), out_channels=16, kernel_size=5\n",
        "        self.conv1 = nn.Conv1d(in_channels=num_channels, out_channels=16, kernel_size=5)\n",
        "        self.bn1 = nn.BatchNorm1d(16)\n",
        "\n",
        "        # Conv2: 16 -> 32\n",
        "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "\n",
        "        # Adaptive pooling to fix output length\n",
        "        self.pool = nn.AdaptiveMaxPool1d(50)  # output length = 50\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(32 * 50, 64)\n",
        "        self.fc2 = nn.Linear(64, num_classes)  # num_classes = 3 (0,1,2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, 3, sequence_length)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))   # -> (batch, 16, L1)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))   # -> (batch, 32, L2)\n",
        "        x = self.pool(x)                       # -> (batch, 32, 50)\n",
        "        x = x.view(x.size(0), -1)             # flatten -> (batch, 32*50)\n",
        "        x = F.relu(self.fc1(x))               # -> (batch, 64)\n",
        "        x = self.fc2(x)                       # -> (batch, num_classes)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Ejl_xfUp8-P3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}